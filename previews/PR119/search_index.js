var documenterSearchIndex = {"docs":
[{"location":"likelihoods/categorical_likelihood/#Categorical-likelihoods","page":"Categorical likelihoods","title":"Categorical likelihoods","text":"","category":"section"},{"location":"likelihoods/categorical_likelihood/","page":"Categorical likelihoods","title":"Categorical likelihoods","text":"CurrentModule = MarkovKernels","category":"page"},{"location":"likelihoods/categorical_likelihood/#Type","page":"Categorical likelihoods","title":"Type","text":"","category":"section"},{"location":"likelihoods/categorical_likelihood/","page":"Categorical likelihoods","title":"Categorical likelihoods","text":"CategoricalLikelihood{A}","category":"page"},{"location":"likelihoods/categorical_likelihood/#MarkovKernels.CategoricalLikelihood","page":"Categorical likelihoods","title":"MarkovKernels.CategoricalLikelihood","text":"CategoricalLikelihood\n\nType for representing a Likelihood function over categories.\n\n\n\n\n\n","category":"type"},{"location":"likelihoods/categorical_likelihood/#Constructor","page":"Categorical likelihoods","title":"Constructor","text":"","category":"section"},{"location":"likelihoods/categorical_likelihood/","page":"Categorical likelihoods","title":"Categorical likelihoods","text":"CategoricalLikelihood(L::Likelihood{<:StochasticMatrix})","category":"page"},{"location":"likelihoods/categorical_likelihood/#MarkovKernels.CategoricalLikelihood-Tuple{Likelihood{<:StochasticMatrix}}","page":"Categorical likelihoods","title":"MarkovKernels.CategoricalLikelihood","text":"CategoricalLikelihood(L::Likelihood{<:StochasticMatrix})\n\nComputes a categorical likelihood from L.\n\n\n\n\n\n","category":"method"},{"location":"likelihoods/categorical_likelihood/#Methods","page":"Categorical likelihoods","title":"Methods","text":"","category":"section"},{"location":"likelihoods/categorical_likelihood/","page":"Categorical likelihoods","title":"Categorical likelihoods","text":"likelihood_vector(L::CategoricalLikelihood)","category":"page"},{"location":"likelihoods/categorical_likelihood/#MarkovKernels.likelihood_vector-Tuple{CategoricalLikelihood}","page":"Categorical likelihoods","title":"MarkovKernels.likelihood_vector","text":"likelihood_vector(L::CategoricalLikelihood)\n\nComputes the vector of likelihood evaluations.\n\n\n\n\n\n","category":"method"},{"location":"likelihoods/likelihood/#Likelihood","page":"Likelihood","title":"Likelihood","text":"","category":"section"},{"location":"likelihoods/likelihood/","page":"Likelihood","title":"Likelihood","text":"CurrentModule = MarkovKernels","category":"page"},{"location":"likelihoods/likelihood/#Type","page":"Likelihood","title":"Type","text":"","category":"section"},{"location":"likelihoods/likelihood/","page":"Likelihood","title":"Likelihood","text":"Likelihood{U,V}","category":"page"},{"location":"likelihoods/likelihood/#MarkovKernels.Likelihood","page":"Likelihood","title":"MarkovKernels.Likelihood","text":"Likelihood{U,V}\n\nType for representing a Likelihood associated with a kernel K(y, x) and a measurement y.\n\n\n\n\n\n","category":"type"},{"location":"likelihoods/likelihood/#Constructors","page":"Likelihood","title":"Constructors","text":"","category":"section"},{"location":"likelihoods/likelihood/","page":"Likelihood","title":"Likelihood","text":"Likelihood(K::AbstractMarkovKernel, y)","category":"page"},{"location":"likelihoods/likelihood/#MarkovKernels.Likelihood-Tuple{AbstractMarkovKernel, Any}","page":"Likelihood","title":"MarkovKernels.Likelihood","text":"Likelihood(K::AbstractMarkovKernel, y)\n\nCreates a Likelihood with measurement kernel K and measurement y.\n\n\n\n\n\n","category":"method"},{"location":"likelihoods/likelihood/#Methods","page":"Likelihood","title":"Methods","text":"","category":"section"},{"location":"likelihoods/likelihood/","page":"Likelihood","title":"Likelihood","text":"measurement_model(L::Likelihood)\nmeasurement(L::Likelihood)","category":"page"},{"location":"likelihoods/likelihood/#MarkovKernels.measurement_model-Tuple{Likelihood}","page":"Likelihood","title":"MarkovKernels.measurement_model","text":"measurement_model(L::Likelihood)\n\nComputes the measurement kernel K.\n\n\n\n\n\n","category":"method"},{"location":"likelihoods/likelihood/#MarkovKernels.measurement-Tuple{Likelihood}","page":"Likelihood","title":"MarkovKernels.measurement","text":"measurement(L::Likelihood)\n\nComputes the measurement y\n\n\n\n\n\n","category":"method"},{"location":"kernels/normalkernel/#NormalKernel","page":"NormalKernel","title":"NormalKernel","text":"","category":"section"},{"location":"kernels/normalkernel/","page":"NormalKernel","title":"NormalKernel","text":"CurrentModule = MarkovKernels","category":"page"},{"location":"kernels/normalkernel/","page":"NormalKernel","title":"NormalKernel","text":"The Normal kernel is denoted by","category":"page"},{"location":"kernels/normalkernel/","page":"NormalKernel","title":"NormalKernel","text":"k(ymid x) = mathcalN(y  mu(x)   Sigma(x) )","category":"page"},{"location":"kernels/normalkernel/","page":"NormalKernel","title":"NormalKernel","text":"As with the Normal distributions, the explicit expression on the kernel depends on whether it is real or complex valued.","category":"page"},{"location":"kernels/normalkernel/#Types","page":"NormalKernel","title":"Types","text":"","category":"section"},{"location":"kernels/normalkernel/","page":"NormalKernel","title":"NormalKernel","text":"AbstractNormalKernel\nNormalKernel","category":"page"},{"location":"kernels/normalkernel/#MarkovKernels.AbstractNormalKernel","page":"NormalKernel","title":"MarkovKernels.AbstractNormalKernel","text":"AbstractNormalKernel\n\nAbstract type for representing Normal kernels.\n\n\n\n\n\n","category":"type"},{"location":"kernels/normalkernel/#MarkovKernels.NormalKernel","page":"NormalKernel","title":"MarkovKernels.NormalKernel","text":"NormalKernel\n\nStandard mean vector / covariance matrix parametrisation of Normal kernels.\n\n\n\n\n\n","category":"type"},{"location":"kernels/normalkernel/#Type-aliases","page":"NormalKernel","title":"Type aliases","text":"","category":"section"},{"location":"kernels/normalkernel/","page":"NormalKernel","title":"NormalKernel","text":"const HomoskedasticNormalKernel{TM,TC} = NormalKernel{<:Homoskedastic,TM,TC} where {TM,TC} # constant conditional covariance\nconst AffineHomoskedasticNormalKernel{TM,TC} =\n    NormalKernel{<:Homoskedastic,TM,TC} where {TM<:AbstractAffineMap,TC} # affine conditional mean, constant conditional covariance\nconst AffineHeteroskedasticNormalKernel{TM,TC} =\n    NormalKernel{<:Heteroskedastic,TM,TC} where {TM<:AbstractAffineMap,TC} # affine conditional mean, non-constant covariance\nconst NonlinearNormalKernel{TM,TC} = NormalKernel{<:Heteroskedastic,TM,TC} where {TM,TC} # the general, nonlinear case","category":"page"},{"location":"kernels/normalkernel/#Constructors","page":"NormalKernel","title":"Constructors","text":"","category":"section"},{"location":"kernels/normalkernel/","page":"NormalKernel","title":"NormalKernel","text":"NormalKernel(μ, Σ)","category":"page"},{"location":"kernels/normalkernel/#MarkovKernels.NormalKernel-Tuple{Any, Any}","page":"NormalKernel","title":"MarkovKernels.NormalKernel","text":"Normal(μ, Σ)\n\nCreates a Normal kernel with conditional mean and covariance parameters μ and  Σ, respectively.\n\n\n\n\n\n","category":"method"},{"location":"kernels/normalkernel/#Methods","page":"NormalKernel","title":"Methods","text":"","category":"section"},{"location":"kernels/normalkernel/","page":"NormalKernel","title":"NormalKernel","text":"mean(K::NormalKernel)\ncov(K::NormalKernel)\ncovp(K::NormalKernel)\nrand(rng::AbstractRNG, K::AbstractNormalKernel, x::AbstractNumOrVec)","category":"page"},{"location":"kernels/normalkernel/#Statistics.mean-Tuple{NormalKernel}","page":"NormalKernel","title":"Statistics.mean","text":"mean(K::AbstractNormalKernel)\n\nComputes the conditonal mean function of the Normal kernel K. That is, the output is callable.\n\n\n\n\n\n","category":"method"},{"location":"kernels/normalkernel/#Statistics.cov-Tuple{NormalKernel}","page":"NormalKernel","title":"Statistics.cov","text":"cov(K::AbstractNormalKernel)\n\nComputes the conditonal covariance function of the Normal kernel K. That is, the output is callable.\n\n\n\n\n\n","category":"method"},{"location":"kernels/normalkernel/#MarkovKernels.covp-Tuple{NormalKernel}","page":"NormalKernel","title":"MarkovKernels.covp","text":"covp(K::AbstractNormalKernel)\n\nReturns the internal representation of the conditonal covariance matrix of the Normal kernel K. For computing the actual conditional covariance matrix, use cov.\n\n\n\n\n\n","category":"method"},{"location":"kernels/normalkernel/#Base.rand-Tuple{Random.AbstractRNG, AbstractNormalKernel, Union{AbstractVector{T}, T} where T<:Number}","page":"NormalKernel","title":"Base.rand","text":"rand([rng::AbstractRNG], K::AbstractNormalKernel, x::AbstractVector)\n\nSamples a random vector conditionally on x with respect the the Normal kernel K using the random number generator rng.\n\n\n\n\n\n","category":"method"},{"location":"PSDParametrizations/internal/#Internal-methods-for-covariance-parameters","page":"Internal","title":"Internal methods for covariance parameters","text":"","category":"section"},{"location":"PSDParametrizations/internal/","page":"Internal","title":"Internal","text":"CurrentModule = MarkovKernels","category":"page"},{"location":"PSDParametrizations/internal/","page":"Internal","title":"Internal","text":"MarkovKernels.utrisqrt2utrichol!\nMarkovKernels.positive_qrwoq!(A::AbstractMatrix)","category":"page"},{"location":"PSDParametrizations/internal/#MarkovKernels.utrisqrt2utrichol!","page":"Internal","title":"MarkovKernels.utrisqrt2utrichol!","text":"utrisqrt2utrichol!(A::AbstractMatrix)\n\nApplies an in-place orthogonal transform to the upper triangular matrix A, such that the diagonal entries are real and positive, i.e. the resulting matrix is a valid Cholesky factor.   \n\n\n\n\n\n","category":"function"},{"location":"PSDParametrizations/internal/#MarkovKernels.positive_qrwoq!-Tuple{AbstractMatrix}","page":"Internal","title":"MarkovKernels.positive_qrwoq!","text":"positive_qrwoq!(A::AbstractMatrix)\n\nComputes the R factor in the QR decomposition of A, in-place, ensuring that the diagonal entries of R are positive. The returned object is a view of A. \n\n\n\n\n\n","category":"method"},{"location":"likelihoods/flatlikelihood/#Flat-likelihoods","page":"Flat likelihoods","title":"Flat likelihoods","text":"","category":"section"},{"location":"likelihoods/flatlikelihood/","page":"Flat likelihoods","title":"Flat likelihoods","text":"CurrentModule = MarkovKernels","category":"page"},{"location":"likelihoods/flatlikelihood/","page":"Flat likelihoods","title":"Flat likelihoods","text":"A flat likelihood, L, acts as ideentity under Bayes' rule, that is:","category":"page"},{"location":"likelihoods/flatlikelihood/","page":"Flat likelihoods","title":"Flat likelihoods","text":"D(x) = fracL(x)D(x)int L(x) D(x) dx","category":"page"},{"location":"likelihoods/flatlikelihood/#Type","page":"Flat likelihoods","title":"Type","text":"","category":"section"},{"location":"likelihoods/flatlikelihood/","page":"Flat likelihoods","title":"Flat likelihoods","text":"FlatLikelihood","category":"page"},{"location":"likelihoods/flatlikelihood/#MarkovKernels.FlatLikelihood","page":"Flat likelihoods","title":"MarkovKernels.FlatLikelihood","text":"FlatLikelihood\n\nType for representing flat likelihoods.\n\n\n\n\n\n","category":"type"},{"location":"likelihoods/likelihood_general/#General","page":"General","title":"General","text":"","category":"section"},{"location":"likelihoods/likelihood_general/","page":"General","title":"General","text":"CurrentModule = MarkovKernels","category":"page"},{"location":"likelihoods/likelihood_general/#Type","page":"General","title":"Type","text":"","category":"section"},{"location":"likelihoods/likelihood_general/","page":"General","title":"General","text":"AbstractLikelihood","category":"page"},{"location":"likelihoods/likelihood_general/#MarkovKernels.AbstractLikelihood","page":"General","title":"MarkovKernels.AbstractLikelihood","text":"AbstractLikelihood\n\nAbstract type for representing likelihood functions.\n\n\n\n\n\n","category":"type"},{"location":"likelihoods/likelihood_general/#Methods","page":"General","title":"Methods","text":"","category":"section"},{"location":"likelihoods/likelihood_general/","page":"General","title":"General","text":"log(::AbstractLikelihood, ::Any)","category":"page"},{"location":"likelihoods/likelihood_general/#Base.log-Tuple{AbstractLikelihood, Any}","page":"General","title":"Base.log","text":"log(L::AbstractLikelihood, x)\n\nComputes the logarithm of L evaluated at x.\n\n\n\n\n\n","category":"method"},{"location":"PSDParametrizations/general/","page":"General","title":"General","text":"CurrentModule = MarkovKernels","category":"page"},{"location":"PSDParametrizations/general/","page":"General","title":"General","text":"MarkovKernels.jl aims to support a wide variety of parametrizations of positive semi-definite matrices. How this is accomplished is explaiend in the following.","category":"page"},{"location":"PSDParametrizations/general/#Types","page":"General","title":"Types","text":"","category":"section"},{"location":"PSDParametrizations/general/","page":"General","title":"General","text":"Currently, the following types are valid PSD parametrizations (in the sense, the PSDParametriszations methods below have been implemented):","category":"page"},{"location":"PSDParametrizations/general/","page":"General","title":"General","text":"Real\nSelfAdjoint\nCholesky","category":"page"},{"location":"PSDParametrizations/general/","page":"General","title":"General","text":"Here, the definition of SelfAdjoint is:","category":"page"},{"location":"PSDParametrizations/general/","page":"General","title":"General","text":"const RealSymmetric{T,S} = Symmetric{T,S} where {T<:Real,S}\nconst ComplexHermitian{T,S} = Hermitian{T,S} where {T<:Complex,S}\nconst RealDiagonal{T,S} = Diagonal{T,S} where {T<:Real,S}\nconst SelfAdjoint{T,S} =\n    Union{RealSymmetric{T,S},ComplexHermitian{T,S},RealDiagonal{T,S}} where {T,S}","category":"page"},{"location":"PSDParametrizations/general/#PSD-Trait","page":"General","title":"PSD Trait","text":"","category":"section"},{"location":"PSDParametrizations/general/","page":"General","title":"General","text":"In order to determine, whether a type is a PSDParametrization the following types are defined:","category":"page"},{"location":"PSDParametrizations/general/","page":"General","title":"General","text":"abstract type PSDTrait end\nstruct IsPSD <: PSDTrait end\nstruct IsNotPSD <: PSDTrait end","category":"page"},{"location":"PSDParametrizations/general/","page":"General","title":"General","text":"A custom typer can opt into being a PSDparametrization by implementing","category":"page"},{"location":"PSDParametrizations/general/","page":"General","title":"General","text":"psdcheck(::MyPSDType) = IsPSD()","category":"page"},{"location":"PSDParametrizations/general/","page":"General","title":"General","text":"which is a promise that the methods of the next section have been implemented.","category":"page"},{"location":"PSDParametrizations/general/#PSDParametrizations-methods","page":"General","title":"PSDParametrizations methods","text":"","category":"section"},{"location":"PSDParametrizations/general/","page":"General","title":"General","text":"psdcheck(::Any)\nconvert_psd_eltype(::Type{T}, P) where {T}\nrsqrt(Σ)\nlsqrt(Σ)\nstein(Σ, Φ, Q)\nschur_reduce(Π, C, R)","category":"page"},{"location":"PSDParametrizations/general/#MarkovKernels.psdcheck-Tuple{Any}","page":"General","title":"MarkovKernels.psdcheck","text":"psdcheck(A)\n\nReturns IsPSD() if A is a PSDParametrization otherwise IsNotPSD()\n\n\n\n\n\n","category":"method"},{"location":"PSDParametrizations/general/#MarkovKernels.convert_psd_eltype-Union{Tuple{T}, Tuple{Type{T}, Any}} where T","page":"General","title":"MarkovKernels.convert_psd_eltype","text":"convert_psd_eltype(::Type{T}, P)\n\nWraps P in a psd paramtrization of eltype T. If P is already a type of psd paramtrization, then just the eltype is converted.\n\n\n\n\n\n","category":"method"},{"location":"PSDParametrizations/general/#MarkovKernels.rsqrt-Tuple{Any}","page":"General","title":"MarkovKernels.rsqrt","text":"rsqrt(Σ)\n\nComputes a right square-root of Σ.\n\n\n\n\n\n","category":"method"},{"location":"PSDParametrizations/general/#MarkovKernels.lsqrt-Tuple{Any}","page":"General","title":"MarkovKernels.lsqrt","text":"lsqrt(Σ)\n\nComputes a left square-root of Σ.\n\n\n\n\n\n","category":"method"},{"location":"PSDParametrizations/general/#MarkovKernels.stein-Tuple{Any, Any, Any}","page":"General","title":"MarkovKernels.stein","text":"stein(Σ, Φ, [Q])\n\nComputes the output of the stein  operator\n\nΣ ↦ Φ * Σ * Φ' + Q.\n\n\n\n\n\n","category":"method"},{"location":"PSDParametrizations/general/#MarkovKernels.schur_reduce-Tuple{Any, Any, Any}","page":"General","title":"MarkovKernels.schur_reduce","text":"schur_reduce(Π, C, [R])\n\nComputes the tuple (S, K, Σ) associated with the following (block) Schur reduction:\n\n[C*Π*C'+R C*Π; Π*C' Π] = [0 0; 0 Σ] + [I; K]*(C*Π*C' + R)*[I; K]'\n\nIn terms of Kalman filtering, Π is the predictive covariance, C the measurement matrix, and R the measurement covariance, then S is the marginal measurement covariance, K is the Kalman gain, and Σ is the filtering covariance.\n\n\n\n\n\n","category":"method"},{"location":"PSDParametrizations/general/#SelfAdjoint-methods","page":"General","title":"SelfAdjoint methods","text":"","category":"section"},{"location":"PSDParametrizations/general/","page":"General","title":"General","text":"Additionally, the following methods are defined for SelfAdjoint:","category":"page"},{"location":"PSDParametrizations/general/","page":"General","title":"General","text":"selfadjoint!(x::Number)\nselfadjoint(A)","category":"page"},{"location":"PSDParametrizations/general/#MarkovKernels.selfadjoint!-Tuple{Number}","page":"General","title":"MarkovKernels.selfadjoint!","text":"selfadjoint!(A)\n\nComputes the self-adjoint part of A, in-place, and wraps it in an appropriate self-adjoint wrapper type (i.e. Symemtric / Hermitian).\n\n\n\n\n\n","category":"method"},{"location":"PSDParametrizations/general/#MarkovKernels.selfadjoint-Tuple{Any}","page":"General","title":"MarkovKernels.selfadjoint","text":"selfadjoint(A)\n\nComputes the self-adjoint part of A and wraps it in an appropriate self-adjoint wrapper type (i.e. Symemtric / Hermitian).\n\n\n\n\n\n","category":"method"},{"location":"binary_operators/","page":"Binary operators","title":"Binary operators","text":"CurrentModule = MarkovKernels","category":"page"},{"location":"binary_operators/#Composition","page":"Binary operators","title":"Composition","text":"","category":"section"},{"location":"binary_operators/","page":"Binary operators","title":"Binary operators","text":"Given Markov kernels k_2(yz) and k_1(zx), composition is a binary operator producing a third kernel k_3(yx) according to","category":"page"},{"location":"binary_operators/","page":"Binary operators","title":"Binary operators","text":"k_3(yx) = int k_2(yx) k_1(zx) mathrmd z","category":"page"},{"location":"binary_operators/","page":"Binary operators","title":"Binary operators","text":"compose(::AbstractMarkovKernel, ::AbstractMarkovKernel)\n∘(K2::AbstractMarkovKernel, K1::AbstractMarkovKernel)","category":"page"},{"location":"binary_operators/#MarkovKernels.compose-Tuple{AbstractMarkovKernel, AbstractMarkovKernel}","page":"Binary operators","title":"MarkovKernels.compose","text":"compose(K2::AbstractMarkovKernel, K1::AbstractMarkovKernel)\n\nComputes K3, the composition of K2 ∘ K1 i.e.,\n\nK3(y,x) = ∫ K2(y,z) K1(z,x) dz.\n\nSee also ∘\n\n\n\n\n\n","category":"method"},{"location":"binary_operators/#Base.:∘-Tuple{AbstractMarkovKernel, AbstractMarkovKernel}","page":"Binary operators","title":"Base.:∘","text":"∘(K2::AbstractMarkovKernel, K1::AbstractMarkovKernel)\n\nComputes K3, the composition of K2 ∘ K1 i.e.,\n\nK3(y,x) = ∫ K2(y,z) K1(z,x) dz.\n\nSee also compose\n\n\n\n\n\n","category":"method"},{"location":"binary_operators/","page":"Binary operators","title":"Binary operators","text":"Additionally, given likelihoods l_1(x) and l_2(x), composition is a binary operator producing a third likelihood l_3(x) according to ","category":"page"},{"location":"binary_operators/","page":"Binary operators","title":"Binary operators","text":"l_3(x) = l_2(x) l_1(x)","category":"page"},{"location":"binary_operators/","page":"Binary operators","title":"Binary operators","text":"compose(::AbstractLikelihood, ::AbstractLikelihood)\n∘(K2::AbstractLikelihood, K1::AbstractLikelihood)","category":"page"},{"location":"binary_operators/#MarkovKernels.compose-Tuple{AbstractLikelihood, AbstractLikelihood}","page":"Binary operators","title":"MarkovKernels.compose","text":"compose(L2::AbstractLikelihood, L1::AbstractLiklelihood)\n\nComputes L3, the composition of L2 ∘ L1 i.e.,\n\nL3(x) = L1(x) * L2(x)\n\nSee also ∘\n\n\n\n\n\n","category":"method"},{"location":"binary_operators/#Base.:∘-Tuple{AbstractLikelihood, AbstractLikelihood}","page":"Binary operators","title":"Base.:∘","text":"∘(K2::AbstractLikelihood, K1::AbstractLikelihood)\n\nComputes L3, the composition of L2 ∘ L1 i.e.,\n\nL3(x) = L1(x) * L2(x)\n\nSee also compose\n\n\n\n\n\n","category":"method"},{"location":"binary_operators/#Algebra","page":"Binary operators","title":"Algebra","text":"","category":"section"},{"location":"binary_operators/","page":"Binary operators","title":"Binary operators","text":"+(D::AbstractDistribution, v::AbstractNumOrVec)\n-(N::Normal)\n-(v::AbstractNumOrVec, D::AbstractDistribution)\n*(C, D::AbstractDistribution)","category":"page"},{"location":"binary_operators/#Base.:+-Tuple{AbstractDistribution, Union{AbstractVector{T}, T} where T<:Number}","page":"Binary operators","title":"Base.:+","text":"+(v::AbstractNumOrVec, D::AbstractDistribution) +(D::AbstractDistribution, v::AbstractNumOrVec)\n\nComputes a translation of D by v, i.e. if x ∼ D then x + v ∼ D + v.\n\n\n\n\n\n","category":"method"},{"location":"binary_operators/#Base.:--Tuple{Normal}","page":"Binary operators","title":"Base.:-","text":"-(D::AbstractDistribution)\n\nComputes the image distribution of D under negation, i.e. if x ∼ D then -x ∼ -D.\n\n\n\n\n\n","category":"method"},{"location":"binary_operators/#Base.:--Tuple{Union{AbstractVector{T}, T} where T<:Number, AbstractDistribution}","page":"Binary operators","title":"Base.:-","text":"-(v::AbstractNumOrVec, D::AbstractDistribution)\n\nEquivalent to +(v, -D).\n\n-(D::AbstractDistribution, v::AbstractNumOrVec)\n\nEquivalent to +(D, -v).\n\n\n\n\n\n","category":"method"},{"location":"binary_operators/#Base.:*-Tuple{Any, AbstractDistribution}","page":"Binary operators","title":"Base.:*","text":"*(C, D::AbstractDistribution)\n\nEquivalent to marginalize(D, DiracKernel(LinearMap(C))).\n\n\n\n\n\n","category":"method"},{"location":"binary_operators/#Marginalization","page":"Binary operators","title":"Marginalization","text":"","category":"section"},{"location":"binary_operators/","page":"Binary operators","title":"Binary operators","text":"Given a distribution pi(x) and a Markov kernel k(yx), marginalization is a binary operator producing a new distriubution p(y) according to","category":"page"},{"location":"binary_operators/","page":"Binary operators","title":"Binary operators","text":"p(y) = int k(y x) pi(x) mathrmd x","category":"page"},{"location":"binary_operators/","page":"Binary operators","title":"Binary operators","text":"marginalize(N::AbstractNormal, K::AffineHomoskedasticNormalKernel)","category":"page"},{"location":"binary_operators/#MarkovKernels.marginalize-Tuple{AbstractNormal, NormalKernel{<:Homoskedastic, TM, TC} where {TM<:AbstractAffineMap, TC}}","page":"Binary operators","title":"MarkovKernels.marginalize","text":"marginalise(D::AbstractDistribution, K::AbstractMarkovKernel)\n\nComputes M, the marginalization of K with respect to D, i.e.,\n\nM(y) = ∫ K(y,x)D(x) dx\n\n\n\n\n\n","category":"method"},{"location":"binary_operators/#Bayes'-rule-and-invert","page":"Binary operators","title":"Bayes' rule & invert","text":"","category":"section"},{"location":"binary_operators/","page":"Binary operators","title":"Binary operators","text":"Given a distribution pi(x) and a Markov kernel k(yx), invert is a binary operator producing a new distribution m(y) and a new Markov kernel p(x  y) according to","category":"page"},{"location":"binary_operators/","page":"Binary operators","title":"Binary operators","text":"pi(x) k(yx) = m(y) p(xy)","category":"page"},{"location":"binary_operators/","page":"Binary operators","title":"Binary operators","text":"The related binary operator, Bayes' rule also evalautes the output of invert at some measurement y. That is, given a measurmeent y, m evaluated at y is the marginal likelihood and p evaluated at y is the conditional distribution of x given y.","category":"page"},{"location":"binary_operators/","page":"Binary operators","title":"Binary operators","text":"invert(N::AbstractDistribution, K::AbstractMarkovKernel)\nposterior_and_loglike(D::AbstractDistribution, K::AbstractMarkovKernel, y)\nposterior_and_loglike(::AbstractDistribution, ::AbstractLikelihood)\nposterior(D::AbstractDistribution, K::AbstractMarkovKernel, y)\nposterior(D::AbstractDistribution, L::AbstractLikelihood)","category":"page"},{"location":"binary_operators/#MarkovKernels.invert-Tuple{AbstractDistribution, AbstractMarkovKernel}","page":"Binary operators","title":"MarkovKernels.invert","text":"invert(D::AbstractDistribution, K::AbstractMarkovKernel)\n\nComputes a new distribution and Markov kernel such that\n\nDout(y) = ∫ K(y, x) D(x) dx, and Kout(x, y) = K(y, x) * D(x) / Dout(y)\n\n\n\n\n\n","category":"method"},{"location":"binary_operators/#MarkovKernels.posterior_and_loglike-Tuple{AbstractDistribution, AbstractMarkovKernel, Any}","page":"Binary operators","title":"MarkovKernels.posterior_and_loglike","text":"posterior_and_loglike(D::AbstractDistribution, K::AbstractMarkovKernel, y)\n\nComputes the conditional distribution C and the marginal log-likelihood ℓ associated with the prior distribution D, measurement kernel K, and measurement y.\n\n\n\n\n\n","category":"method"},{"location":"binary_operators/#MarkovKernels.posterior_and_loglike-Tuple{AbstractDistribution, AbstractLikelihood}","page":"Binary operators","title":"MarkovKernels.posterior_and_loglike","text":"posterior_and_loglike(D::AbstractDistribution, L::AbstractLikelihood)\n\nComputes the conditional distribution C and the marginal log-likelihood ℓ associated with the prior distribution D and the likelihood L.\n\n\n\n\n\n","category":"method"},{"location":"binary_operators/#MarkovKernels.posterior-Tuple{AbstractDistribution, AbstractMarkovKernel, Any}","page":"Binary operators","title":"MarkovKernels.posterior","text":"posterior(D::AbstractDistribution, K::AbstractMarkovKernel, y)\n\nComputes the conditional distribution C associated with the prior distribution D, measurement kernel K, and measurement y.\n\n\n\n\n\n","category":"method"},{"location":"binary_operators/#MarkovKernels.posterior-Tuple{AbstractDistribution, AbstractLikelihood}","page":"Binary operators","title":"MarkovKernels.posterior","text":"posterior(D::AbstractDistribution, L::AbstractLikelihood)\n\nComputes the conditional distribution C associated with the prior distribution D and the likelihood L.\n\n\n\n\n\n","category":"method"},{"location":"binary_operators/#Doob's-h-transform","page":"Binary operators","title":"Doob's h-transform","text":"","category":"section"},{"location":"binary_operators/","page":"Binary operators","title":"Binary operators","text":"Given a Markov kernel k(y x) and a likelihood function h(y), computes a new Markov kernel f(y x) and new likelihood function","category":"page"},{"location":"binary_operators/","page":"Binary operators","title":"Binary operators","text":"htransform(::AbstractMarkovKernel, ::AbstractLikelihood)","category":"page"},{"location":"binary_operators/#MarkovKernels.htransform-Tuple{AbstractMarkovKernel, AbstractLikelihood}","page":"Binary operators","title":"MarkovKernels.htransform","text":"htransform(K::AbstractMarkov, L::AbstractLikelihood)\n\nComputes a Markov kernel Kout and Likelihood Lout such that\n\nLout(z) = ∫ L(x) K(x, z) dx, and Kout(x, z) = L(x) K(x, z) / Lout(z)\n\n\n\n\n\n","category":"method"},{"location":"kernels/kernel_general/#General","page":"General","title":"General","text":"","category":"section"},{"location":"kernels/kernel_general/","page":"General","title":"General","text":"CurrentModule = MarkovKernels","category":"page"},{"location":"kernels/kernel_general/#Type","page":"General","title":"Type","text":"","category":"section"},{"location":"kernels/kernel_general/","page":"General","title":"General","text":"AbstractMarkovKernel","category":"page"},{"location":"kernels/kernel_general/#MarkovKernels.AbstractMarkovKernel","page":"General","title":"MarkovKernels.AbstractMarkovKernel","text":"AbstractMarkovKernel\n\nAbstract type for representing Markov kernels.\n\n\n\n\n\n","category":"type"},{"location":"kernels/kernel_general/#Methods","page":"General","title":"Methods","text":"","category":"section"},{"location":"kernels/kernel_general/","page":"General","title":"General","text":"condition(::AbstractMarkovKernel, ::Any)","category":"page"},{"location":"kernels/kernel_general/#MarkovKernels.condition-Tuple{AbstractMarkovKernel, Any}","page":"General","title":"MarkovKernels.condition","text":"condition(K::AbstractMarkovKernel, x)\n\nComputes the distribution retrieved from evaluating K at x.\n\n\n\n\n\n","category":"method"},{"location":"distributions/dirac/#Dirac","page":"Dirac","title":"Dirac","text":"","category":"section"},{"location":"distributions/dirac/","page":"Dirac","title":"Dirac","text":"CurrentModule = MarkovKernels","category":"page"},{"location":"distributions/dirac/","page":"Dirac","title":"Dirac","text":"The Dirac distribution with parameter mu is a distribution putting all probabiltiy mass on mu. It is denoted by","category":"page"},{"location":"distributions/dirac/","page":"Dirac","title":"Dirac","text":"delta(x -mu)","category":"page"},{"location":"distributions/dirac/#Types","page":"Dirac","title":"Types","text":"","category":"section"},{"location":"distributions/dirac/","page":"Dirac","title":"Dirac","text":"AbstractDirac{T}\nDirac{T}","category":"page"},{"location":"distributions/dirac/#MarkovKernels.AbstractDirac","page":"Dirac","title":"MarkovKernels.AbstractDirac","text":"AbstractDirac{ST}\n\nAbstract type for representing Dirac distributions taking values in ST.\n\n\n\n\n\n","category":"type"},{"location":"distributions/dirac/#MarkovKernels.Dirac","page":"Dirac","title":"MarkovKernels.Dirac","text":"Dirac\n\nType for representing Dirac distributions with sample_eltype ST.\n\n\n\n\n\n","category":"type"},{"location":"distributions/dirac/#Constructors","page":"Dirac","title":"Constructors","text":"","category":"section"},{"location":"distributions/dirac/","page":"Dirac","title":"Dirac","text":"Dirac(μ::AbstractVector)","category":"page"},{"location":"distributions/dirac/#MarkovKernels.Dirac-Tuple{AbstractVector}","page":"Dirac","title":"MarkovKernels.Dirac","text":"Dirac(μ)\n\nCreates a Dirac distribution with mean μ.\n\n\n\n\n\n","category":"method"},{"location":"distributions/dirac/#Methods","page":"Dirac","title":"Methods","text":"","category":"section"},{"location":"distributions/dirac/","page":"Dirac","title":"Dirac","text":"dim(::Dirac)\nmean(::Dirac)","category":"page"},{"location":"distributions/dirac/#MarkovKernels.dim-Tuple{Dirac}","page":"Dirac","title":"MarkovKernels.dim","text":"dim(D::AbstractDirac)\n\nReturns the dimension of the Dirac distribution D.\n\n\n\n\n\n","category":"method"},{"location":"distributions/dirac/#Statistics.mean-Tuple{Dirac}","page":"Dirac","title":"Statistics.mean","text":"mean(D::AbstractDirac)\n\nComputes the mean vector of the Dirac distribution D.\n\n\n\n\n\n","category":"method"},{"location":"tutorial_kalman_filter/#Kalman-filtering-and-smoothing","page":"Kalman filtering and smoothing","title":"Kalman filtering and smoothing","text":"","category":"section"},{"location":"tutorial_kalman_filter/","page":"Kalman filtering and smoothing","title":"Kalman filtering and smoothing","text":"This tutorial describes how to perform filtering and smoothing in a the probabilistic state-space model given by","category":"page"},{"location":"tutorial_kalman_filter/","page":"Kalman filtering and smoothing","title":"Kalman filtering and smoothing","text":"beginaligned\nx_0 sim mathcalN(mu_0 Sigma_0) \nx_n mid x_n-1 sim mathcalN(Phi  x_n-1 Q)\nz_n = C x_n\nendaligned","category":"page"},{"location":"tutorial_kalman_filter/","page":"Kalman filtering and smoothing","title":"Kalman filtering and smoothing","text":"subject to the measurements given by","category":"page"},{"location":"tutorial_kalman_filter/","page":"Kalman filtering and smoothing","title":"Kalman filtering and smoothing","text":"y_n mid x_n sim mathcalN(Cx_nR)","category":"page"},{"location":"tutorial_kalman_filter/#Setting-up-the-environment-and-generating-some-data","page":"Kalman filtering and smoothing","title":"Setting up the environment and generating some data","text":"","category":"section"},{"location":"tutorial_kalman_filter/","page":"Kalman filtering and smoothing","title":"Kalman filtering and smoothing","text":"using MarkovKernels\nusing Random, LinearAlgebra, Plots, IterTools\n\nrng = MersenneTwister(1991)\n\nfunction sample(rng, init, K, nstep)\n    it = Iterators.take(iterated(z -> rand(rng, K, z), rand(rng, init)), nstep + 1)\n    return mapreduce(permutedims, vcat, collect(it))\nend\n\n# time grid\nm = 200\nT = 5\nts = collect(LinRange(0, T, m))\ndt = T / (m - 1)\n\n# define transtion kernel\nλ = 2.0\nΦ = LinearMap( exp(-λ * dt) .* [1.0 0.0; -2*λ*dt 1.0] )\nQ = Symmetric(I - exp(-2 * λ * dt) .* [1.0 -2*λ*dt; -2*λ*dt 1+(2*λ*dt)^2])\nfw_kernel = NormalKernel(Φ, Q)\n\n# initial distribution\ninit = Normal(zeros(2), Symmetric(diagm(ones(2))))\n\n# sample state\nxs = sample(rng, init, fw_kernel, m - 1)\n\n# output kernel and measurement kernel\nC = LinearMap( adjoint([1.0, -1.0]) / sqrt(2))\noutput_kernel = DiracKernel(C)\nR = 0.1\nm_kernel = compose(NormalKernel(LinearMap(1.0), R), output_kernel)\n\n# sample output and its measurements\nzs = mapreduce(z -> rand(rng, output_kernel, xs[z, :]), vcat, 1:m)\nys = mapreduce(z -> rand(rng, m_kernel, xs[z, :]), vcat, 1:m)\n\noutput_plot = plot(ts, zs, label = \"output\", xlabel = \"t\")\nscatter!(ts, ys, label = \"measurement\", color = \"black\")","category":"page"},{"location":"tutorial_kalman_filter/#Implementing-a-Kalman-filter","page":"Kalman filtering and smoothing","title":"Implementing a Kalman filter","text":"","category":"section"},{"location":"tutorial_kalman_filter/","page":"Kalman filtering and smoothing","title":"Kalman filtering and smoothing","text":"function kalman_filter(\n    ys::AbstractVector,\n    init::AbstractNormal,\n    fw_kernel::AbstractNormalKernel,\n    m_kernel::AbstractNormalKernel,\n)\n\n    # initialise recursion\n    filter_distribution = init\n    filter_distributions = typeof(init)[]\n\n    # initial measurement update\n    likelihood = Likelihood(m_kernel, ys[1])\n    filter_distribution, loglike_increment = posterior_and_loglike(filter_distribution, likelihood)\n    push!(filter_distributions, filter_distribution)\n    loglike = loglike_increment\n\n    for m in 2:size(ys, 1)\n\n        # predict\n        filter_distribution = marginalize(filter_distribution, fw_kernel)\n\n        # measurement update\n        likelihood = Likelihood(m_kernel, ys[m])\n        filter_distribution, loglike_increment = posterior_and_loglike(filter_distribution, likelihood)\n        push!(filter_distributions, filter_distribution)\n        loglike = loglike + loglike_increment\n    end\n\n    return filter_distributions, loglike\nend\nnothing # hide","category":"page"},{"location":"tutorial_kalman_filter/#Computing-the-filtered-state-estimates","page":"Kalman filtering and smoothing","title":"Computing the filtered state estimates","text":"","category":"section"},{"location":"tutorial_kalman_filter/","page":"Kalman filtering and smoothing","title":"Kalman filtering and smoothing","text":"filter_distributions, loglike = kalman_filter(ys, init, fw_kernel, m_kernel)\n\nstate_filter_plt = plot(\n    ts,\n    xs,\n    layout = (2, 1),\n    xlabel = [\"\" \"t\"],\n    label = [\"x1\" \"x2\"],\n    title = [\"Filter estimates of the state\" \"\"],\n)\nplot!(ts, filter_distributions, layout = (2, 1), label = [\"x1filter\" \"x2filter\"])","category":"page"},{"location":"tutorial_kalman_filter/#Computing-the-filtered-output-estimates","page":"Kalman filtering and smoothing","title":"Computing the filtered output estimates","text":"","category":"section"},{"location":"tutorial_kalman_filter/","page":"Kalman filtering and smoothing","title":"Kalman filtering and smoothing","text":"output_filter_estimate = map(z -> marginalize(z, output_kernel), filter_distributions)\n\noutput_filter_plt = plot(ts, zs, label = \"output\", xlabel = \"t\")\nscatter!(ts, ys, label = \"measurement\", color = \"black\")\nplot!(ts, output_filter_estimate, label = \"filter estimate\")","category":"page"},{"location":"tutorial_kalman_filter/#Implementing-a-Rauch-Tung-Striebel-recursion","page":"Kalman filtering and smoothing","title":"Implementing a Rauch-Tung-Striebel recursion","text":"","category":"section"},{"location":"tutorial_kalman_filter/","page":"Kalman filtering and smoothing","title":"Kalman filtering and smoothing","text":"function rts(filter_distributions, fw_kernel)\n    smoother_distribution = filter_distributions[end]\n    smoother_distributions = similar(filter_distributions)\n    smoother_distributions[end] = smoother_distribution\n\n    for m in length(smoother_distributions)-1:-1:1\n        pred, bw_kernel = invert(filter_distributions[m], fw_kernel)\n        smoother_distribution = marginalize(smoother_distribution, bw_kernel)\n        smoother_distributions[m] = smoother_distribution\n    end\n\n    return smoother_distributions\nend\nnothing # hide","category":"page"},{"location":"tutorial_kalman_filter/#Computing-the-smoothed-state-estimate","page":"Kalman filtering and smoothing","title":"Computing the smoothed state estimate","text":"","category":"section"},{"location":"tutorial_kalman_filter/","page":"Kalman filtering and smoothing","title":"Kalman filtering and smoothing","text":"smoother_distributions = rts(filter_distributions, fw_kernel)\n\nstate_smoother_plt = plot(\n    ts,\n    xs,\n    layout = (2, 1),\n    xlabel = [\"\" \"t\"],\n    label = [\"x1\" \"x2\"],\n    title = [\"Smoother estimates of the state\" \"\"],\n)\nplot!(ts, smoother_distributions, layout = (2, 1), label = [\"x1smoother\" \"x2smoother\"])","category":"page"},{"location":"tutorial_kalman_filter/#Computing-the-smoothed-output-estimate","page":"Kalman filtering and smoothing","title":"Computing the smoothed output estimate","text":"","category":"section"},{"location":"tutorial_kalman_filter/","page":"Kalman filtering and smoothing","title":"Kalman filtering and smoothing","text":"output_smoother_estimate = map(z -> marginalize(z, output_kernel), smoother_distributions)\noutput_smoother_plt = plot(ts, zs, label = \"output\", xlabel = \"t\")\nscatter!(ts, ys, label = \"measurement\", color = \"black\")\nplot!(ts, output_smoother_estimate, label = \"smoother estimate\")","category":"page"},{"location":"distributions/categorical/#Categorical","page":"Categorical","title":"Categorical","text":"","category":"section"},{"location":"distributions/categorical/#Types","page":"Categorical","title":"Types","text":"","category":"section"},{"location":"distributions/categorical/","page":"Categorical","title":"Categorical","text":"AbstractCategorical{T}\nCategorical{T}","category":"page"},{"location":"distributions/categorical/#MarkovKernels.AbstractCategorical","page":"Categorical","title":"MarkovKernels.AbstractCategorical","text":"AbstractCategorical{ST}\n\nAbstract type for representing categorical distributions with values ST.\n\n\n\n\n\n","category":"type"},{"location":"distributions/categorical/#MarkovKernels.Categorical","page":"Categorical","title":"MarkovKernels.Categorical","text":"Categorical{T,A}\n\nType for representing categorical distributions with sample_eltype T.\n\n\n\n\n\n","category":"type"},{"location":"distributions/categorical/#Constructor","page":"Categorical","title":"Constructor","text":"","category":"section"},{"location":"distributions/categorical/","page":"Categorical","title":"Categorical","text":"Categorical(p::AbstractVector)","category":"page"},{"location":"distributions/categorical/#MarkovKernels.Categorical-Tuple{AbstractVector}","page":"Categorical","title":"MarkovKernels.Categorical","text":"Categorical(p::AbstractVector)\n\nConstructs a categorical distribution from the vector of probabilities p.\n\n\n\n\n\n","category":"method"},{"location":"distributions/categorical/#Methods","page":"Categorical","title":"Methods","text":"","category":"section"},{"location":"distributions/categorical/","page":"Categorical","title":"Categorical","text":"probability_vector(::AbstractCategorical)\nentropy(C::AbstractCategorical)\nkldivergence(C1::AbstractCategorical, C2::AbstractCategorical)","category":"page"},{"location":"distributions/categorical/#MarkovKernels.probability_vector-Tuple{AbstractCategorical}","page":"Categorical","title":"MarkovKernels.probability_vector","text":"probability_vector(::AbstractCategorical)\n\nComputes the vector of probabilities for each category.\n\n\n\n\n\n","category":"method"},{"location":"distributions/categorical/#MarkovKernels.entropy-Tuple{AbstractCategorical}","page":"Categorical","title":"MarkovKernels.entropy","text":"entropy(C::AbstractCategorical)\n\nComputes the entropy of the categorical distribution C.\n\n\n\n\n\n","category":"method"},{"location":"distributions/categorical/#MarkovKernels.kldivergence-Tuple{AbstractCategorical, AbstractCategorical}","page":"Categorical","title":"MarkovKernels.kldivergence","text":"kldivergence(C1::AbstractCategorical, C2::AbstractCategorical)\n\nComputes the Kullback-Leibler divergence between the categorical distributions C1 and C2.\n\n\n\n\n\n","category":"method"},{"location":"tutorials/gauss_markov_regression/#Sampling-and-inference-in-Gauss-Markov-models","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"","category":"section"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"Gauss-Markov realizable signal:","category":"page"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"beginaligned\nx_0 sim mathcalN(mu_0 Sigma_0) \nx_t mid x_u sim mathcalN( Phi_t u x_u Q_t u) \ns_t mid x_t sim delta(cdotp - C x_t)\nendaligned","category":"page"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"Transition parameters:","category":"page"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"beginaligned\nPhi_t u = e^A (t - u)\nQ_t u = sqrtt-u int_0^1 e^A(t-u)z B B^* e^A^*(t-u)z mathrmd z\nendaligned","category":"page"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"Observations:","category":"page"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"y_t_k mid s_t_k sim mathcalN(s_t_k R)","category":"page"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"using MarkovKernels\nusing FiniteHorizonGramians\nusing Random, LinearAlgebra, Plots\nrng = Random.Xoshiro(19910215)\n\nnothing # hide","category":"page"},{"location":"tutorials/gauss_markov_regression/#Implementing-samplers-for-Gauss-Markov-realizable-signals","page":"Sampling and inference in Gauss-Markov models","title":"Implementing samplers for Gauss-Markov realizable signals","text":"","category":"section"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"\nnothing # hide","category":"page"},{"location":"tutorials/gauss_markov_regression/#Defining-a-Gauss-Markov-realizable-signal-and-sampling-it","page":"Sampling and inference in Gauss-Markov models","title":"Defining a Gauss-Markov realizable signal and sampling it","text":"","category":"section"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"\nnothing # hide","category":"page"},{"location":"tutorials/gauss_markov_regression/#Plotting-the-realization","page":"Sampling and inference in Gauss-Markov models","title":"Plotting the realization","text":"","category":"section"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"\nnothing # hide","category":"page"},{"location":"tutorials/gauss_markov_regression/#Implementing-the-forward-algorithm","page":"Sampling and inference in Gauss-Markov models","title":"Implementing the forward algorithm","text":"","category":"section"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"The forward algorithm operates on a sequence of a posteriori terminal distributions (so-called filtering distributions):","category":"page"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"p(x_t mid y_0t)","category":"page"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"The algorithm first initializes by:","category":"page"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"beginaligned\np(y_0) = int p(y_0 mid x_0) p(x_0) mathrmd x_0 \np(x_0 mid y_0) = p(y_0 mid x_0) p(x_0)\nendaligned","category":"page"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"These two equations are implemented by posterior_and_loglike. The algorithm then computes a sequence of filtering distributions, reverse-time transition kernels, and accumulates the log-likelihood of the observations according to the following forward recursion:","category":"page"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"beginaligned\np(x_t mid y_0t-1) = int p(x_t mid x_t-1) p(x_t-1 mid y_0t-1) mathrmd x_t-1 \np(x_t-1 mid x_t y_0T) = p(x_t mid x_t-1) p(x_t-1 mid y_0t-1)  p(x_t mid y_0t-1) \np(y_t mid y_0t-1) = int p(y_t mid x_t) p(x_t mid y_0t-1) mathrmd x_t \nlog p(y_0t) = log p(y_0t-1) + log p(y_t mid y_0t-1)\nendaligned","category":"page"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"The first two equations are implemented by invert and the last two equations are, again, implemented by posterior_and_loglike. Using MarkovKernels.jl, the code might look something like the following:","category":"page"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"\nnothing # hide","category":"page"},{"location":"tutorials/gauss_markov_regression/#Computing-a-reverse-time-Markov-a-posteriori-path-distribution","page":"Sampling and inference in Gauss-Markov models","title":"Computing a reverse-time Markov a posteriori path-distribution","text":"","category":"section"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"\nnothing # hide","category":"page"},{"location":"tutorials/gauss_markov_regression/#Computing-a-posteriori-time-marginals","page":"Sampling and inference in Gauss-Markov models","title":"Computing a posteriori time-marginals","text":"","category":"section"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"The a posteriori time marginals may be computed according to the following backward recursion:","category":"page"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"p(x_t-1 mid y_0T) = int p(x_t-1 mid x_t y_0T) p(x_t mid y_0T) mathrmd x_t","category":"page"},{"location":"tutorials/gauss_markov_regression/","page":"Sampling and inference in Gauss-Markov models","title":"Sampling and inference in Gauss-Markov models","text":"This equation is implemented by marginalize. Using MarkovKernels.jl, the code might look something like the following:","category":"page"},{"location":"tutorials/gauss_markov_regression/#Plotting-the-a-posteriori-time-marginals-and-some-samples","page":"Sampling and inference in Gauss-Markov models","title":"Plotting the a posteriori time marginals and some samples","text":"","category":"section"},{"location":"kernels/dirackernel/#DiracKernel","page":"DiracKernel","title":"DiracKernel","text":"","category":"section"},{"location":"kernels/dirackernel/","page":"DiracKernel","title":"DiracKernel","text":"CurrentModule = MarkovKernels","category":"page"},{"location":"kernels/dirackernel/","page":"DiracKernel","title":"DiracKernel","text":"The Dirac kernel with conditional mean prameter  mu is denotd by","category":"page"},{"location":"kernels/dirackernel/","page":"DiracKernel","title":"DiracKernel","text":"k(ymid x) = delta(y - mu(x))","category":"page"},{"location":"kernels/dirackernel/#Types","page":"DiracKernel","title":"Types","text":"","category":"section"},{"location":"kernels/dirackernel/","page":"DiracKernel","title":"DiracKernel","text":"AbstractDiracKernel\nDiracKernel\nIdentityKernel","category":"page"},{"location":"kernels/dirackernel/#MarkovKernels.AbstractDiracKernel","page":"DiracKernel","title":"MarkovKernels.AbstractDiracKernel","text":"AbstractDiracKernel\n\nAbstract type for representing Dirac kernels.\n\n\n\n\n\n","category":"type"},{"location":"kernels/dirackernel/#MarkovKernels.DiracKernel","page":"DiracKernel","title":"MarkovKernels.DiracKernel","text":"DiracKernel\n\nType for representing Dirac kernels K(y,x) = δ(y - μ(x)).\n\n\n\n\n\n","category":"type"},{"location":"kernels/dirackernel/#MarkovKernels.IdentityKernel","page":"DiracKernel","title":"MarkovKernels.IdentityKernel","text":"IdentityKernel\n\nStruct for representing kernels that act like identity under marginalization.\n\n\n\n\n\n","category":"type"},{"location":"kernels/dirackernel/#Type-aliases","page":"DiracKernel","title":"Type aliases","text":"","category":"section"},{"location":"kernels/dirackernel/","page":"DiracKernel","title":"DiracKernel","text":"const AffineDiracKernel{T} = DiracKernel{T,<:AbstractAffineMap}","category":"page"},{"location":"kernels/dirackernel/#Methods","page":"DiracKernel","title":"Methods","text":"","category":"section"},{"location":"kernels/dirackernel/","page":"DiracKernel","title":"DiracKernel","text":"mean(K::DiracKernel)\nrand(::AbstractRNG, K::AbstractDiracKernel, x::AbstractNumOrVec)","category":"page"},{"location":"kernels/dirackernel/#Statistics.mean-Tuple{DiracKernel}","page":"DiracKernel","title":"Statistics.mean","text":"mean(K::AbstractDiracKernel)\n\nComputes the conditonal mean function of the Dirac kernel K. That is, the output is callable.\n\n\n\n\n\n","category":"method"},{"location":"kernels/dirackernel/#Base.rand-Tuple{Random.AbstractRNG, AbstractDiracKernel, Union{AbstractVector{T}, T} where T<:Number}","page":"DiracKernel","title":"Base.rand","text":"rand([rng::AbstractRNG], K::AbstractDiracKernel, x::AbstractVector)\n\nComputes a random vector conditionally on x with respect the the Dirac kernel K using the random number generator RNG. Equivalent to mean(K)(x).\n\n\n\n\n\n","category":"method"},{"location":"kernels/stochasticmatrix/#StochasticMatrix","page":"StochasticMatrix","title":"StochasticMatrix","text":"","category":"section"},{"location":"kernels/stochasticmatrix/","page":"StochasticMatrix","title":"StochasticMatrix","text":"CurrentModule = MarkovKernels","category":"page"},{"location":"kernels/stochasticmatrix/#Types","page":"StochasticMatrix","title":"Types","text":"","category":"section"},{"location":"kernels/stochasticmatrix/","page":"StochasticMatrix","title":"StochasticMatrix","text":"AbstractStochasticMatrix\nStochasticMatrix","category":"page"},{"location":"kernels/stochasticmatrix/#MarkovKernels.AbstractStochasticMatrix","page":"StochasticMatrix","title":"MarkovKernels.AbstractStochasticMatrix","text":"AbstractStochasticMatrix\n\nAbstract type for representing stochastic matrices.\n\n\n\n\n\n","category":"type"},{"location":"kernels/stochasticmatrix/#MarkovKernels.StochasticMatrix","page":"StochasticMatrix","title":"MarkovKernels.StochasticMatrix","text":"StochasticMatrix\n\nType for representing stochastic matrices.\n\n\n\n\n\n","category":"type"},{"location":"kernels/stochasticmatrix/#Constructor","page":"StochasticMatrix","title":"Constructor","text":"","category":"section"},{"location":"kernels/stochasticmatrix/","page":"StochasticMatrix","title":"StochasticMatrix","text":"StochasticMatrix(P::AbstractMatrix)","category":"page"},{"location":"kernels/stochasticmatrix/#MarkovKernels.StochasticMatrix-Tuple{AbstractMatrix}","page":"StochasticMatrix","title":"MarkovKernels.StochasticMatrix","text":"StochasticMatrix(P::AbstractMatrix)\n\nConstructs a stochastic matrix from the matrix of transition probabilities P.\n\n\n\n\n\n","category":"method"},{"location":"kernels/stochasticmatrix/#Methods","page":"StochasticMatrix","title":"Methods","text":"","category":"section"},{"location":"kernels/stochasticmatrix/","page":"StochasticMatrix","title":"StochasticMatrix","text":"probability_matrix(::AbstractStochasticMatrix)\nrand(rng::AbstractRNG, K::AbstractStochasticMatrix, x::Int)","category":"page"},{"location":"kernels/stochasticmatrix/#MarkovKernels.probability_matrix-Tuple{AbstractStochasticMatrix}","page":"StochasticMatrix","title":"MarkovKernels.probability_matrix","text":"probability_vector(::AbstractCategorical)\n\nComputes the matrix of transition probabilities.\n\n\n\n\n\n","category":"method"},{"location":"kernels/stochasticmatrix/#Base.rand-Tuple{Random.AbstractRNG, AbstractStochasticMatrix, Int64}","page":"StochasticMatrix","title":"Base.rand","text":"rand([rng::AbstractRNG], K::AbstractStochasticMatrix, x)\n\nSamples a random vector conditionally on x with respect the the stochastic matrix K using the random number generator rng.\n\n\n\n\n\n","category":"method"},{"location":"distributions/distribution_general/#General","page":"General","title":"General","text":"","category":"section"},{"location":"distributions/distribution_general/","page":"General","title":"General","text":"CurrentModule = MarkovKernels","category":"page"},{"location":"distributions/distribution_general/#Type","page":"General","title":"Type","text":"","category":"section"},{"location":"distributions/distribution_general/","page":"General","title":"General","text":"AbstractDistribution{T<:Number}","category":"page"},{"location":"distributions/distribution_general/#MarkovKernels.AbstractDistribution","page":"General","title":"MarkovKernels.AbstractDistribution","text":"AbstractDistribution{ST}\n\nAbstract type for representing distributions with samples of type ST.\n\n\n\n\n\n","category":"type"},{"location":"distributions/distribution_general/#Type-information","page":"General","title":"Type information","text":"","category":"section"},{"location":"distributions/distribution_general/","page":"General","title":"General","text":"sample_type(D::AbstractDistribution)\nsample_eltype(D::AbstractDistribution)","category":"page"},{"location":"distributions/distribution_general/#MarkovKernels.sample_type-Tuple{AbstractDistribution}","page":"General","title":"MarkovKernels.sample_type","text":"sample_type(D::AbstractDistribution)\n\nComputes the type of samples from D, e.g. same as typeof(rand(D)).\n\n\n\n\n\n","category":"method"},{"location":"distributions/distribution_general/#MarkovKernels.sample_eltype-Tuple{AbstractDistribution}","page":"General","title":"MarkovKernels.sample_eltype","text":"sample_eltype(D::AbstractDistribution)\n\nComputes the eltype of samples from D, e.g. same as eltype(rand(D)).\n\n\n\n\n\n","category":"method"},{"location":"distributions/distribution_general/#Probability-densities","page":"General","title":"Probability densities","text":"","category":"section"},{"location":"distributions/distribution_general/","page":"General","title":"General","text":"logpdf(D::AbstractDistribution, x)","category":"page"},{"location":"distributions/distribution_general/#MarkovKernels.logpdf-Tuple{AbstractDistribution, Any}","page":"General","title":"MarkovKernels.logpdf","text":"logpdf(D::AbstractDistribution, x)\n\nComputes the logarithm of the probabilidty density of D, evaluated at x.\n\n\n\n\n\n","category":"method"},{"location":"distributions/distribution_general/#Sampling","page":"General","title":"Sampling","text":"","category":"section"},{"location":"distributions/distribution_general/","page":"General","title":"General","text":"Base.rand(rng::AbstractRNG, D::AbstractDistribution)","category":"page"},{"location":"distributions/distribution_general/#Base.rand-Tuple{Random.AbstractRNG, AbstractDistribution}","page":"General","title":"Base.rand","text":"rand([rng], D::AbstractDistribution)\n\nDraws one sample from D.\n\n\n\n\n\n","category":"method"},{"location":"likelihoods/logquadratic/#Log-quadratic-likelihoods","page":"Log-quadratic likelihoods","title":"Log-quadratic likelihoods","text":"","category":"section"},{"location":"likelihoods/logquadratic/","page":"Log-quadratic likelihoods","title":"Log-quadratic likelihoods","text":"CurrentModule = MarkovKernels","category":"page"},{"location":"likelihoods/logquadratic/#Type","page":"Log-quadratic likelihoods","title":"Type","text":"","category":"section"},{"location":"likelihoods/logquadratic/","page":"Log-quadratic likelihoods","title":"Log-quadratic likelihoods","text":"LogQuadraticLikelihood{A,B,C}","category":"page"},{"location":"likelihoods/logquadratic/#MarkovKernels.LogQuadraticLikelihood","page":"Log-quadratic likelihoods","title":"MarkovKernels.LogQuadraticLikelihood","text":"LogQuadraticLikelihood\n\nType for representing log-quadratic likelihoods.\n\n\n\n\n\n","category":"type"},{"location":"likelihoods/logquadratic/#Constructor","page":"Log-quadratic likelihoods","title":"Constructor","text":"","category":"section"},{"location":"likelihoods/logquadratic/","page":"Log-quadratic likelihoods","title":"Log-quadratic likelihoods","text":"LogQuadraticLikelihood(L::Likelihood{<:AffineHomoskedasticNormalKernel})","category":"page"},{"location":"likelihoods/logquadratic/#MarkovKernels.LogQuadraticLikelihood-Tuple{Likelihood{<:NormalKernel{<:Homoskedastic, TM, TC} where {TM<:AbstractAffineMap, TC}}}","page":"Log-quadratic likelihoods","title":"MarkovKernels.LogQuadraticLikelihood","text":"LogQuadraticLikelihood(L::Likelihood{<:AffineHomoskedasticNormalKernel})\n\nComputes a log-quadratic likelihood from L.\n\n\n\n\n\n","category":"method"},{"location":"tutorials/hidden_markov_model/#Sampling-and-inference-in-Hidden-Markov-models","page":"Sampling and inference in Hidden Markov models","title":"Sampling and inference in Hidden Markov models","text":"","category":"section"},{"location":"tutorials/hidden_markov_model/","page":"Sampling and inference in Hidden Markov models","title":"Sampling and inference in Hidden Markov models","text":"A finite state hidden Markov model is specified by an initial distribution, a sequence of transition probabilities, and a sequence of observation probabilities:","category":"page"},{"location":"tutorials/hidden_markov_model/","page":"Sampling and inference in Hidden Markov models","title":"Sampling and inference in Hidden Markov models","text":"beginaligned\nP(x_0 = i) \nP(x_t = i mid x_t-1 = j) quad t = 1 ldots T   \nP(y_t = i mid x_t = j) quad t = 0 1 ldots T\nendaligned","category":"page"},{"location":"tutorials/hidden_markov_model/","page":"Sampling and inference in Hidden Markov models","title":"Sampling and inference in Hidden Markov models","text":"This tutorial describes how to use MarkovKernels.jl to:","category":"page"},{"location":"tutorials/hidden_markov_model/","page":"Sampling and inference in Hidden Markov models","title":"Sampling and inference in Hidden Markov models","text":"Sample from a (finite state) hidden Markov model\nCompute the a posteriori distribution of the hidden sequence using the backward recursion","category":"page"},{"location":"tutorials/hidden_markov_model/","page":"Sampling and inference in Hidden Markov models","title":"Sampling and inference in Hidden Markov models","text":"using MarkovKernels\nusing Random, LinearAlgebra, Plots\nimport Plots\nrng = Random.Xoshiro(19910215)\n\nnothing # hide","category":"page"},{"location":"tutorials/hidden_markov_model/#Implementing-samplers-for-finite-state-(hidden)-Markov-models","page":"Sampling and inference in Hidden Markov models","title":"Implementing samplers for finite state (hidden) Markov models","text":"","category":"section"},{"location":"tutorials/hidden_markov_model/","page":"Sampling and inference in Hidden Markov models","title":"Sampling and inference in Hidden Markov models","text":"function sample(rng::AbstractRNG, init, fw_kernels)\n    x = rand(rng, init)\n    n = length(fw_kernels) + 1\n    xs = Vector{typeof(x)}(undef, n)\n    xs[begin] = x\n\n    for (m, fw_kernel) in pairs(fw_kernels)\n        x = rand(rng, condition(fw_kernel, x))\n        xs[begin+m] = x\n    end\n    return xs\nend\n\nfunction sample(rng::AbstractRNG, init, fw_kernels, obs_kernels)\n    # sample initial values\n    x = rand(rng, init)\n    y = rand(rng, first(obs_kernels), x)\n\n    # allocate output\n    n = length(obs_kernels)\n    xs = Vector{typeof(x)}(undef, n)\n    ys = Vector{typeof(y)}(undef, n)\n\n    xs[begin] = x\n    ys[begin] = y\n\n    for (m, fw_kernel) in pairs(fw_kernels)\n        obs_kernel = obs_kernels[begin+m]\n        x = rand(rng, condition(fw_kernel, x))\n        y = rand(rng, condition(obs_kernel, x))\n        xs[begin+m] = x\n        ys[begin+m] = y\n    end\n    return xs, ys\nend\n\nnothing # hide","category":"page"},{"location":"tutorials/hidden_markov_model/#Defining-a-finite-state-hidden-Markov-model-and-sampling-it","page":"Sampling and inference in Hidden Markov models","title":"Defining a finite state hidden Markov model and sampling it","text":"","category":"section"},{"location":"tutorials/hidden_markov_model/","page":"Sampling and inference in Hidden Markov models","title":"Sampling and inference in Hidden Markov models","text":"# number of possible hidden states and number of possible observation states\nm, n = 10, 10\n\n# probability vector of initial distribution\ninit = Categorical(ones(m))\n\n# transition probabilities\nPxx = Matrix(Tridiagonal(ones(m - 1), 5 * ones(m), ones(m - 1)))\nKxx = StochasticMatrix(Pxx)\n\n# observation probabilites\nPyx = (ones(m, m) - I)\nKyx = StochasticMatrix(Pyx)\n\nT = 2^8 + 1\nfw_kernels = fill(Kxx, T - 1)\nobs_kernels = fill(Kyx, T)\n\n# sample hidden and observed states\nxs, ys = sample(rng, init, fw_kernels, obs_kernels)\nnothing # hide","category":"page"},{"location":"tutorials/hidden_markov_model/#Plotting-the-realization","page":"Sampling and inference in Hidden Markov models","title":"Plotting the realization","text":"","category":"section"},{"location":"tutorials/hidden_markov_model/","page":"Sampling and inference in Hidden Markov models","title":"Sampling and inference in Hidden Markov models","text":"hmm_plt = Plots.scatter(\n    layout = (1, 2)\n)\nPlots.scatter!(\n    hmm_plt,\n    eachindex(xs),\n    xs,\n    color = \"black\",\n    subplot = 1,\n    title = \"hidden states\",\n    label = \"\",\n)\nPlots.scatter!(\n    hmm_plt,\n    eachindex(ys),\n    ys,\n    color = \"red\",\n    subplot = 2,\n    title = \"observation states\",\n    label = \"\",\n)","category":"page"},{"location":"tutorials/hidden_markov_model/#Implementing-the-backward-algorithms","page":"Sampling and inference in Hidden Markov models","title":"Implementing the backward algorithms","text":"","category":"section"},{"location":"tutorials/hidden_markov_model/","page":"Sampling and inference in Hidden Markov models","title":"Sampling and inference in Hidden Markov models","text":"The backward algorith operates on the sequence of likelihoods of future observations:","category":"page"},{"location":"tutorials/hidden_markov_model/","page":"Sampling and inference in Hidden Markov models","title":"Sampling and inference in Hidden Markov models","text":"h_tT mid s(x) = P(y_tT mid x_s = x)","category":"page"},{"location":"tutorials/hidden_markov_model/","page":"Sampling and inference in Hidden Markov models","title":"Sampling and inference in Hidden Markov models","text":"It computes an a posteriori initial distribution, a sequence of a posteriori transition probabilities, and a log-likelihood of the observations, via a backward recursion. The recursion is given by:","category":"page"},{"location":"tutorials/hidden_markov_model/","page":"Sampling and inference in Hidden Markov models","title":"Sampling and inference in Hidden Markov models","text":"beginaligned\nh_tTmid t-1(z) = sum_x h_tT mid t(x) P(x_t = x mid x_t-1 = z)  \nP(x_t = x mid x_t-1 = z y_0T) = h_tT mid t(x) P(x_t = x mid x_t-1 = z)  h_tTmid t-1(z) \nh_t-1T mid t-1(x) = h_tTmid t-1(x) h_t-1 mid t-1(x)\nendaligned","category":"page"},{"location":"tutorials/hidden_markov_model/","page":"Sampling and inference in Hidden Markov models","title":"Sampling and inference in Hidden Markov models","text":"The first two equations are implemented by htransform and the last equation is implemented by compose. The algorithm terminates by computing the a posteriori initial distribution and the log-likelihood of the observations:","category":"page"},{"location":"tutorials/hidden_markov_model/","page":"Sampling and inference in Hidden Markov models","title":"Sampling and inference in Hidden Markov models","text":"beginaligned\nlog P(y_0T) =  log Big(sum_x h_0T mid 0(x) P(x_0 = x) Big) \nP(x_0 = x mid y_0T) = h_0T mid 0(x) P(x_0 = x)  P(y_0T)\nendaligned","category":"page"},{"location":"tutorials/hidden_markov_model/","page":"Sampling and inference in Hidden Markov models","title":"Sampling and inference in Hidden Markov models","text":"These equations are implemented by posterior_and_loglike. Using MarkovKernels.jl, the code might look something like the following:","category":"page"},{"location":"tutorials/hidden_markov_model/","page":"Sampling and inference in Hidden Markov models","title":"Sampling and inference in Hidden Markov models","text":"function backward_recursion(init, forward_kernels, likelihoods)\n    h = last(likelihoods)\n    KT = Base.promote_op(first ∘ htransform, eltype(forward_kernels), typeof(h))\n    post_forward_kernels = Vector{KT}(undef, length(forward_kernels))\n\n    for m in eachindex(forward_kernels)\n        fw_kernel = forward_kernels[end-m+1]\n        post_fw_kernel, h = htransform(fw_kernel, h)\n        post_forward_kernels[end-m+1] = post_fw_kernel\n\n        like = likelihoods[end-m]\n        h = compose(h, like)\n    end\n    post_init, loglike = posterior_and_loglike(init, h)\n    return post_init, post_forward_kernels, loglike\nend\n\nnothing # hide","category":"page"},{"location":"tutorials/hidden_markov_model/#Computing-the-a-posteriori-distribution-of-the-hidden-sequence","page":"Sampling and inference in Hidden Markov models","title":"Computing the a posteriori distribution of the hidden sequence","text":"","category":"section"},{"location":"tutorials/hidden_markov_model/","page":"Sampling and inference in Hidden Markov models","title":"Sampling and inference in Hidden Markov models","text":"likes = [Likelihood(Kobs, y) for (Kobs, y) in zip(obs_kernels, ys)] # compute the likelihoods associated with the observations\npost_init, post_fw_kernels, loglike = backward_recursion(init, fw_kernels, likes)\n\nnothing # hide","category":"page"},{"location":"tutorials/hidden_markov_model/#Sampling-a-posteriori-hidden-sequences-and-plotting-them","page":"Sampling and inference in Hidden Markov models","title":"Sampling a posteriori hidden sequences and plotting them","text":"","category":"section"},{"location":"tutorials/hidden_markov_model/","page":"Sampling and inference in Hidden Markov models","title":"Sampling and inference in Hidden Markov models","text":"    nsample = 10\n    for _ in 1:nsample\n        xs_post = sample(rng, post_init, post_fw_kernels)\n        Plots.scatter!(\n            hmm_plt,\n            eachindex(xs_post),\n            xs_post,\n            label = \"\",\n            color = \"blue\",\n            alpha = 0.1,\n            )\n    end\nhmm_plt","category":"page"},{"location":"affinemaps/affinemaps/#Affine-maps","page":"Affine maps","title":"Affine maps","text":"","category":"section"},{"location":"affinemaps/affinemaps/","page":"Affine maps","title":"Affine maps","text":"An affine map is a function f given by","category":"page"},{"location":"affinemaps/affinemaps/","page":"Affine maps","title":"Affine maps","text":" f(x) = A x + b","category":"page"},{"location":"affinemaps/affinemaps/","page":"Affine maps","title":"Affine maps","text":"where A is the slope and b is the intercept. Different representations of affine maps are sometimes useful, as documented below.","category":"page"},{"location":"affinemaps/affinemaps/","page":"Affine maps","title":"Affine maps","text":"CurrentModule = MarkovKernels","category":"page"},{"location":"affinemaps/affinemaps/#Types","page":"Affine maps","title":"Types","text":"","category":"section"},{"location":"affinemaps/affinemaps/","page":"Affine maps","title":"Affine maps","text":"AbstractAffineMap{T<:Number}\nAffineMap{T,U,V}\nLinearMap{T,U}\nAffineCorrector{T,U,V,S}","category":"page"},{"location":"affinemaps/affinemaps/#MarkovKernels.AbstractAffineMap","page":"Affine maps","title":"MarkovKernels.AbstractAffineMap","text":"AbstractAffineMap{T<:Number}\n\nAbstract type for representing affine maps between vector spaces over the field determined by T.\n\n\n\n\n\n","category":"type"},{"location":"affinemaps/affinemaps/#MarkovKernels.AffineMap","page":"Affine maps","title":"MarkovKernels.AffineMap","text":"AffineMap{T,U,V}\n\nType for representing affine maps in the standard slope / intercept parametrisation.\n\n\n\n\n\n","category":"type"},{"location":"affinemaps/affinemaps/#MarkovKernels.LinearMap","page":"Affine maps","title":"MarkovKernels.LinearMap","text":"LinearMap{T,U}\n\nType for representing affine maps with zero intercept.\n\n\n\n\n\n","category":"type"},{"location":"affinemaps/affinemaps/#MarkovKernels.AffineCorrector","page":"Affine maps","title":"MarkovKernels.AffineCorrector","text":"AffineCorrector{T,U,V,S}\n\nType for representing affine correctors, i.e.,\n\nx ↦ b + A * (x -c).\n\n\n\n\n\n","category":"type"},{"location":"affinemaps/affinemaps/#Constructors","page":"Affine maps","title":"Constructors","text":"","category":"section"},{"location":"affinemaps/affinemaps/","page":"Affine maps","title":"Affine maps","text":"AffineMap(A::AbstractMatrix, b::AbstractVector)\nLinearMap(A::AbstractMatrix)\nAffineCorrector(A::AbstractMatrix, b::AbstractVector, c::AbstractVector)","category":"page"},{"location":"affinemaps/affinemaps/#MarkovKernels.AffineMap-Tuple{AbstractMatrix, AbstractVector}","page":"Affine maps","title":"MarkovKernels.AffineMap","text":"AffineMap(A, b)\n\nCreates an AffineMap with slope A and intercept b.\n\n\n\n\n\n","category":"method"},{"location":"affinemaps/affinemaps/#MarkovKernels.LinearMap-Tuple{AbstractMatrix}","page":"Affine maps","title":"MarkovKernels.LinearMap","text":"LinearMap(A::AbstractMatrix)\n\nCreates a LinearMap with slope A.\n\n\n\n\n\n","category":"method"},{"location":"affinemaps/affinemaps/#MarkovKernels.AffineCorrector-Tuple{AbstractMatrix, AbstractVector, AbstractVector}","page":"Affine maps","title":"MarkovKernels.AffineCorrector","text":"AffineCorrector(A, b, c)\n\nCreates an Affine Corrector with slope A and intercept b - A * c.\n\n\n\n\n\n","category":"method"},{"location":"affinemaps/affinemaps/#Basics","page":"Affine maps","title":"Basics","text":"","category":"section"},{"location":"affinemaps/affinemaps/","page":"Affine maps","title":"Affine maps","text":"slope(F::AffineMap)\nintercept(F::AffineMap)\ncompose(F2::AbstractAffineMap, F1::AbstractAffineMap)\n∘(F2::AbstractAffineMap, F1::AbstractAffineMap)","category":"page"},{"location":"affinemaps/affinemaps/#MarkovKernels.slope-Tuple{AffineMap}","page":"Affine maps","title":"MarkovKernels.slope","text":"slope(F::AbstractAffineMap)\n\nComputes the slope of F.\n\n\n\n\n\n","category":"method"},{"location":"affinemaps/affinemaps/#MarkovKernels.intercept-Tuple{AffineMap}","page":"Affine maps","title":"MarkovKernels.intercept","text":"intercept(F::AffineMap)\n\nComputes the intercept of F.\n\n\n\n\n\n","category":"method"},{"location":"affinemaps/affinemaps/#MarkovKernels.compose-Tuple{AbstractAffineMap, AbstractAffineMap}","page":"Affine maps","title":"MarkovKernels.compose","text":"compose(F2::AbstractAffineMap, F1::AbstractAffineMap)\n\nComputes the affine map F3 resulting from the composition F2 ∘ F1.\n\nSee also ∘\n\n\n\n\n\n","category":"method"},{"location":"affinemaps/affinemaps/#Base.:∘-Tuple{AbstractAffineMap, AbstractAffineMap}","page":"Affine maps","title":"Base.:∘","text":"∘(F2::AbstractAffineMap, F1::AbstractAffineMap)\n\nEquivalent to compose(F2::AbstractAffineMap, F1::AbstractAffineMap).\n\nSee also compose\n\n\n\n\n\n","category":"method"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = MarkovKernels\nusing MarkovKernels","category":"page"},{"location":"#MarkovKernels","page":"Home","title":"MarkovKernels","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for MarkovKernels.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"distributions/normal/#Normal","page":"Normal","title":"Normal","text":"","category":"section"},{"location":"distributions/normal/","page":"Normal","title":"Normal","text":"CurrentModule = MarkovKernels","category":"page"},{"location":"distributions/normal/","page":"Normal","title":"Normal","text":"The standard parametrisation of the Normal distribution is given by","category":"page"},{"location":"distributions/normal/","page":"Normal","title":"Normal","text":"mathcalN(x  mu   Sigma )","category":"page"},{"location":"distributions/normal/","page":"Normal","title":"Normal","text":"where mu is the mean vector and Sigma is the covariance matrix. The exact expression for the probabiltiy density function depends on whether x is vector with real or complex values, both are supported. For real valued vectors the density function is given by","category":"page"},{"location":"distributions/normal/","page":"Normal","title":"Normal","text":"mathcalN(x  mu   Sigma ) = 2pi Sigma^-12 exp Big(  -frac12(x-mu)^* Sigma^-1 (x-mu)  Big)","category":"page"},{"location":"distributions/normal/","page":"Normal","title":"Normal","text":"whereas for complex valued vectors the density function is given by","category":"page"},{"location":"distributions/normal/","page":"Normal","title":"Normal","text":"mathcalN(x  mu   Sigma ) = pi Sigma^-1 exp Big(  -(x-mu)^* Sigma^-1 (x-mu)  Big)","category":"page"},{"location":"distributions/normal/#Types","page":"Normal","title":"Types","text":"","category":"section"},{"location":"distributions/normal/","page":"Normal","title":"Normal","text":"AbstractNormal{T}\nNormal{T}","category":"page"},{"location":"distributions/normal/#MarkovKernels.AbstractNormal","page":"Normal","title":"MarkovKernels.AbstractNormal","text":"AbstractNormal{ST}\n\nAbstract type for representing Normal distributed random vectors taking values in ST.\n\n\n\n\n\n","category":"type"},{"location":"distributions/normal/#MarkovKernels.Normal","page":"Normal","title":"MarkovKernels.Normal","text":"Normal{ST,U,V}\n\nStandard mean vector / covariance matrix parametrization of the Normal distribution with sample type ST.\n\n\n\n\n\n","category":"type"},{"location":"distributions/normal/#Constructors","page":"Normal","title":"Constructors","text":"","category":"section"},{"location":"distributions/normal/","page":"Normal","title":"Normal","text":"Normal(μ::AbstractVector, Σ)","category":"page"},{"location":"distributions/normal/#MarkovKernels.Normal-Tuple{AbstractVector, Any}","page":"Normal","title":"MarkovKernels.Normal","text":"Normal(μ, Σ)\n\nCreates a Normal distribution with mean μ and covariance Σ.\n\n\n\n\n\n","category":"method"},{"location":"distributions/normal/#Methods","page":"Normal","title":"Methods","text":"","category":"section"},{"location":"distributions/normal/","page":"Normal","title":"Normal","text":"dim(::Normal)\nmean(::Normal)\ncov(::Normal)\ncovp(::Normal)\nvar(::AbstractNormal)\nstd(::AbstractNormal)\nresidual(N::AbstractNormal, x::AbstractVector)\nentropy(::AbstractNormal)\nkldivergence(N1::AbstractNormal, N2::AbstractNormal)","category":"page"},{"location":"distributions/normal/#MarkovKernels.dim-Tuple{Normal}","page":"Normal","title":"MarkovKernels.dim","text":"dim(N::AbstractNormal)\n\nReturns the dimension of the Normal distribution N.\n\n\n\n\n\n","category":"method"},{"location":"distributions/normal/#Statistics.mean-Tuple{Normal}","page":"Normal","title":"Statistics.mean","text":"mean(N::AbstractNormal)\n\nComputes the mean vector of the Normal distribution N.\n\n\n\n\n\n","category":"method"},{"location":"distributions/normal/#Statistics.cov-Tuple{Normal}","page":"Normal","title":"Statistics.cov","text":"cov(N::AbstractNormal)\n\nComputes the covariance matrix of the Normal distribution N.\n\n\n\n\n\n","category":"method"},{"location":"distributions/normal/#MarkovKernels.covp-Tuple{Normal}","page":"Normal","title":"MarkovKernels.covp","text":"covp(N::AbstractNormal)\n\nReturns the internal representation of the covariance matrix of the Normal distribution N. For computing the actual covariance matrix, use cov.\n\n\n\n\n\n","category":"method"},{"location":"distributions/normal/#Statistics.var-Tuple{AbstractNormal}","page":"Normal","title":"Statistics.var","text":"var(N::AbstractNormal)\n\nComputes the vector of marginal variances of the Normal distribution N.\n\n\n\n\n\n","category":"method"},{"location":"distributions/normal/#Statistics.std-Tuple{AbstractNormal}","page":"Normal","title":"Statistics.std","text":"std(N::AbstractNormal)\n\nComputes the vector of marginal standard deviations of the Normal distribution N.\n\n\n\n\n\n","category":"method"},{"location":"distributions/normal/#MarkovKernels.residual-Tuple{AbstractNormal, AbstractVector}","page":"Normal","title":"MarkovKernels.residual","text":"residual(N::AbstractNormal, x::AbstractVector)\n\nComputes the whitened residual associated with the Normal distribution N and observed vector x.\n\n\n\n\n\n","category":"method"},{"location":"distributions/normal/#MarkovKernels.entropy-Tuple{AbstractNormal}","page":"Normal","title":"MarkovKernels.entropy","text":"entropy(N::AbstractNormal)\n\nComputes the entropy of the Normal distribution N.\n\n\n\n\n\n","category":"method"},{"location":"distributions/normal/#MarkovKernels.kldivergence-Tuple{AbstractNormal, AbstractNormal}","page":"Normal","title":"MarkovKernels.kldivergence","text":"kldivergence(N1::AbstractNormal, N2::AbstractNormal)\n\nComputes the Kullback-Leibler divergence between the Normal distributions N1 and N2.\n\n\n\n\n\n","category":"method"}]
}
